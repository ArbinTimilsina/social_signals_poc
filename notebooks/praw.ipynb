{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0692b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "CLASSIFICATION_THRESHOLD = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706ad777",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_ID = os.getenv(\"reddit_id\")\n",
    "REDDIT_SECRET = os.getenv(\"reddit_secret\")\n",
    "REDDIT_USERNAME = os.getenv(\"reddit_username\")\n",
    "REDDIT_PASSWORD = os.getenv(\"reddit_password\")\n",
    "\n",
    "def get_reddit():\n",
    "    reddit = praw.Reddit(\n",
    "        user_agent=\"SocialSignals/1.0\",\n",
    "        client_id=REDDIT_ID,\n",
    "        client_secret=REDDIT_SECRET,\n",
    "        username=REDDIT_USERNAME,\n",
    "        password=REDDIT_PASSWORD,\n",
    "    )\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e80805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_TOKEN = os.getenv(\"huggingface_token\")\n",
    "\n",
    "NER_MODEL_ID = \"dslim/bert-large-NER\"\n",
    "EMOTION_MODEL_ID = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "ESG_CATEGORIES_MODEL_ID = \"yiyanghkust/finbert-esg-9-categories\"\n",
    "\n",
    "\n",
    "def get_huggingface_response(text, model_id):\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_TOKEN}\"}\n",
    "\n",
    "    payload = {\"inputs\": text, \"options\": {\"wait_for_model\": True}}\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    \n",
    "    try:\n",
    "        response = response.json()\n",
    "    except Exception:\n",
    "        print(f\"Could not get Huggingface response for {model_id}\")\n",
    "        return \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6390130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "OPENAI_KEY = os.getenv(\"openai_key\")\n",
    "openai.api_key = OPENAI_KEY\n",
    "\n",
    "def get_openai_summary(text):\n",
    "    prompt = f\"{text} \\n\\nTl;dr\"\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            temperature=0.7,\n",
    "            max_tokens=60,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=1\n",
    "            )\n",
    "    except Exception:\n",
    "        print(\"Could not get OpenAI response\")\n",
    "        return \n",
    "    return response[\"choices\"][0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e633cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':\\nThanks!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is nice\"\n",
    "get_openai_summary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65864b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\r\n",
      "Version: 0.27.6\r\n",
      "Summary: Python client library for the OpenAI API\r\n",
      "Home-page: https://github.com/openai/openai-python\r\n",
      "Author: OpenAI\r\n",
      "Author-email: support@openai.com\r\n",
      "License: \r\n",
      "Location: /opt/anaconda3/envs/social-signals-env/lib/python3.8/site-packages\r\n",
      "Requires: aiohttp, requests, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285a20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(submission, comment_sort=\"top\", comment_limit=10):\n",
    "    \"\"\"\n",
    "    comment_sort: Can be one of: \"confidence\", \"controversial\", \"new\", \"old\", \"q&a\", and \"top\"\n",
    "    \"\"\"\n",
    "    # Calling replace_more() access comments, and so must be done after comment_sort is updated\n",
    "    submission.comment_sort = comment_sort\n",
    "    submission.comment_limit = comment_limit\n",
    "\n",
    "    # Remove comments like \"load more comments”, and “continue this thread”\n",
    "    submission.comments.replace_more(limit=0)\n",
    "\n",
    "    comments = submission.comments\n",
    "    return comments\n",
    "\n",
    "\n",
    "def process_submission_data(\n",
    "    submission_id, submission_title, comment_sort=\"top\", comment_limit=10\n",
    "):\n",
    "    reddit = get_reddit()\n",
    "    submission = reddit.submission(submission_id)\n",
    "\n",
    "    assert submission.title == submission_title, \"Miss-match in submission title!\"\n",
    "\n",
    "    submission_data = {}\n",
    "\n",
    "    submission_url = submission.url\n",
    "    submission_data[\"url\"] = submission_url\n",
    "\n",
    "    print(\"Getting emotion for the title...\")\n",
    "    title_emotion = get_huggingface_response(submission_title, EMOTION_MODEL_ID)\n",
    "    if isinstance(title_emotion, list):\n",
    "        title_emotion_prediction = title_emotion[0][0][\"label\"]\n",
    "        title_emotion_score = title_emotion[0][0][\"score\"]\n",
    "        if title_emotion_score >= CLASSIFICATION_THRESHOLD:\n",
    "            submission_data[\"title_emotion\"] = title_emotion_prediction\n",
    "        else:\n",
    "            submission_data[\"title_emotion\"] = \"neutral\"\n",
    "\n",
    "    print(\"Getting ESG categories for the title...\")\n",
    "    title_esg_categories = get_huggingface_response(\n",
    "        submission_title, ESG_CATEGORIES_MODEL_ID\n",
    "    )\n",
    "    if isinstance(title_esg_categories, list):\n",
    "        title_esg_categories_prediction = title_esg_categories[0][0][\"label\"]\n",
    "        title_esg_categories_score = title_esg_categories[0][0][\"score\"]\n",
    "        if title_esg_categories_score:\n",
    "            submission_data[\"categories\"] = title_esg_categories_prediction\n",
    "\n",
    "    print(\"Going over comments...\")\n",
    "    top_level_comments = get_comments(\n",
    "        submission=submission, comment_sort=comment_sort, comment_limit=comment_limit\n",
    "    )\n",
    "    comments_emotion_counter, comments = {}, []\n",
    "    for top_level_comment in top_level_comments:\n",
    "        comment = top_level_comment.body\n",
    "        comments.append(comment)\n",
    "\n",
    "        comment_emotion = get_huggingface_response(comment, EMOTION_MODEL_ID)\n",
    "\n",
    "        if isinstance(comment_emotion, list):\n",
    "            comment_emotion_prediction = comment_emotion[0][0][\"label\"]\n",
    "            comment_emotion_score = comment_emotion[0][0][\"score\"]\n",
    "            comment_emotion_score = round(comment_emotion_score, 2)\n",
    "            if comment_emotion_score >= CLASSIFICATION_THRESHOLD:\n",
    "                comments_emotion_counter[comment_emotion_prediction] = (\n",
    "                    comments_emotion_counter.get(comment_emotion_prediction, 0) + 1\n",
    "                )\n",
    "    if comments_emotion_counter:\n",
    "        submission_data[\"comments_emotion\"] = max(\n",
    "            comments_emotion_counter, key=comments_emotion_counter.get\n",
    "        )\n",
    "    else:\n",
    "        submission_data[\"comments_emotion\"] = NONE_FILLER\n",
    "\n",
    "    if comments:\n",
    "        summary_text = \" \".join(comments)\n",
    "        summary = get_openai_summary(summary_text)\n",
    "\n",
    "        submission_data[\"comments_summary\"] = summary\n",
    "    else:\n",
    "        submission_data[\"comments_summary\"] = NONE_FILLER\n",
    "\n",
    "    return submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37800a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "NONE_FILLER = \"000\"\n",
    "COMMENT_SORT = \"top\"\n",
    "COMMENT_LIMIT = 15\n",
    "\n",
    "def get_submission_data(year, month, day, df, entity, top_n=3):\n",
    "    df = df[df[entity] != NONE_FILLER]\n",
    "    for _, row in df.head(n=top_n).iterrows():\n",
    "        submission_id = row[\"submission_id\"]\n",
    "        submission_title = row[\"submission_title\"]\n",
    "        submission_data = process_submission_data(\n",
    "            submission_id=submission_id,\n",
    "            submission_title=submission_title,\n",
    "            comment_sort=COMMENT_SORT,\n",
    "            comment_limit=COMMENT_LIMIT,\n",
    "        )\n",
    "        submission_data[\"bucket\"] = entity\n",
    "        submission_data[\"year\"] = year\n",
    "        submission_data[\"day\"] = day\n",
    "        submission_data[\"month\"] = month\n",
    "        submission_data[\"title\"] = submission_title\n",
    "\n",
    "        subreddit_name = row[\"subreddit_name\"]\n",
    "        submission_data[\"source\"] = f\"reddit.com/r/{subreddit_name}\"\n",
    "\n",
    "        entities = row[entity]\n",
    "        submission_data[\"tags\"] = entities\n",
    "\n",
    "        return submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69935fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>organization</th>\n",
       "      <th>person</th>\n",
       "      <th>location</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>submission_score</th>\n",
       "      <th>submission_num_comments</th>\n",
       "      <th>submission_rank</th>\n",
       "      <th>comment_rank</th>\n",
       "      <th>social_signals_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>13m0o5c</td>\n",
       "      <td>Kyle Dubas not returning as Maple Leafs genera...</td>\n",
       "      <td>Maple Leafs</td>\n",
       "      <td>Kyle Dubas</td>\n",
       "      <td>000</td>\n",
       "      <td>20640023</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>13l6lx9</td>\n",
       "      <td>Disney Pulls Plug on $1 Billion Development in...</td>\n",
       "      <td>Disney P</td>\n",
       "      <td>000</td>\n",
       "      <td>Florida</td>\n",
       "      <td>8324813</td>\n",
       "      <td>42321</td>\n",
       "      <td>2423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.353610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>13lqabu</td>\n",
       "      <td>Report: The National Archives Is Set to Hand O...</td>\n",
       "      <td>National Archives</td>\n",
       "      <td>Trump, Trump</td>\n",
       "      <td>White House</td>\n",
       "      <td>8324813</td>\n",
       "      <td>23755</td>\n",
       "      <td>1226</td>\n",
       "      <td>0.561301</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.199606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>13l6ykk</td>\n",
       "      <td>Disney scraps plans for new Florida campus, ma...</td>\n",
       "      <td>Disney</td>\n",
       "      <td>000</td>\n",
       "      <td>Florida</td>\n",
       "      <td>26168448</td>\n",
       "      <td>59786</td>\n",
       "      <td>4206</td>\n",
       "      <td>0.449402</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.161967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>13lc2wb</td>\n",
       "      <td>Ron DiSaster Loses $1 Billion Disney Project D...</td>\n",
       "      <td>000</td>\n",
       "      <td>Ron DiSaster, Ron DeSantis</td>\n",
       "      <td>000</td>\n",
       "      <td>8324813</td>\n",
       "      <td>16637</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.393109</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.141617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit_name submission_id   \n",
       "0         sports       13m0o5c  \\\n",
       "1       politics       13l6lx9   \n",
       "2       politics       13lqabu   \n",
       "3           news       13l6ykk   \n",
       "4       politics       13lc2wb   \n",
       "\n",
       "                                    submission_title       organization   \n",
       "0  Kyle Dubas not returning as Maple Leafs genera...        Maple Leafs  \\\n",
       "1  Disney Pulls Plug on $1 Billion Development in...           Disney P   \n",
       "2  Report: The National Archives Is Set to Hand O...  National Archives   \n",
       "3  Disney scraps plans for new Florida campus, ma...             Disney   \n",
       "4  Ron DiSaster Loses $1 Billion Disney Project D...                000   \n",
       "\n",
       "                       person     location  subreddit_subscribers   \n",
       "0                  Kyle Dubas          000               20640023  \\\n",
       "1                         000      Florida                8324813   \n",
       "2                Trump, Trump  White House                8324813   \n",
       "3                         000      Florida               26168448   \n",
       "4  Ron DiSaster, Ron DeSantis          000                8324813   \n",
       "\n",
       "   submission_score  submission_num_comments  submission_rank  comment_rank   \n",
       "0                 1                        8         0.000000      1.000000  \\\n",
       "1             42321                     2423         1.000000      0.005554   \n",
       "2             23755                     1226         0.561301      0.004848   \n",
       "3             59786                     4206         0.449402      0.007194   \n",
       "4             16637                     1038         0.393109      0.006198   \n",
       "\n",
       "   social_signals_rank  \n",
       "0             0.650000  \n",
       "1             0.353610  \n",
       "2             0.199606  \n",
       "3             0.161967  \n",
       "4             0.141617  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"s3://social-signals-dev-data/reddit/year=2023/month=05/day=18/combined.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "698594d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting emotion for the title...\n",
      "Getting ESG categories for the title...\n",
      "Going over comments...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.sportsnet.ca/nhl/article/kyle-dubas-not-returning-as-maple-leafs-general-manager/',\n",
       " 'title_emotion': 'sadness',\n",
       " 'categories': 'Corporate Governance',\n",
       " 'comments_emotion': 'surprise',\n",
       " 'comments_summary': ' - The Toronto Maple Leafs have “parted ways” with Kyle Dubas, which was unexpected given his success in improving the roster and finding good value players.',\n",
       " 'bucket': 'organization',\n",
       " 'year': '2023',\n",
       " 'day': '18',\n",
       " 'month': '05',\n",
       " 'title': 'Kyle Dubas not returning as Maple Leafs general manager',\n",
       " 'source': 'reddit.com/r/sports',\n",
       " 'tags': 'Maple Leafs'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "month = \"05\"\n",
    "day = \"18\"\n",
    "submission_data_organization = get_submission_data(year, month, day, df, entity=\"organization\")\n",
    "submission_data_organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a225f897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "TABLE_NAME = \"social_signals_poc\"\n",
    "SCHEMA = \"social_signals_dev\"\n",
    "IF_EXISTS = \"append\"\n",
    "\n",
    "def get_engine():\n",
    "    username = os.getenv(\"db_username\")\n",
    "    password = urllib.parse.quote(os.getenv(\"db_password\"))\n",
    "    host = os.getenv(\"db_host\")\n",
    "    port = os.getenv(\"db_port\")\n",
    "    name = os.getenv(\"db_name\")\n",
    "    engine = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{name}\"\n",
    "\n",
    "    return engine\n",
    "\n",
    "db_df = pd.DataFrame(data=[submission_data_organization])\n",
    "engine = get_engine()\n",
    "connection = create_engine(engine, pool_pre_ping=True)\n",
    "\n",
    "db_df.to_sql(\n",
    "    TABLE_NAME,\n",
    "    connection,\n",
    "    schema=SCHEMA,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101f0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social-signals-env",
   "language": "python",
   "name": "social-signals-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
